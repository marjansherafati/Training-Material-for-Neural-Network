{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Network for classifying Iris flowers",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marjansherafati/Training-Material-for-Neural-Network/blob/master/Neural_Network_for_classifying_Iris_flowers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jNkbki51g2Z",
        "colab_type": "text"
      },
      "source": [
        "# Building a Neural Network to classify Iris flowers\n",
        "\n",
        "in this notebook, we will use the Python **scikit learn** library to build a neural network on the Iris dataset.\n",
        "\n",
        "\n",
        "Scikit Learn (sklearn) is an open source python library for machine learning and provides many supervised and unsupervised training algorithms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgzrBwSM6ucl",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n",
        "The first step is to import this dataset into our program. We will do so using python's **Pandas** library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UPtDySh1aew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Location of dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "\n",
        "# Assign colum names to the dataset\n",
        "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
        "\n",
        "# Read dataset to pandas dataframe\n",
        "irisdata = pd.read_csv(url, names=names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fptPzkkQ6-g9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "let's see what the dataset looks like\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P2NU8Hu68-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4b90fe39-8143-476e-ddfb-71956fa17ab5"
      },
      "source": [
        "irisdata.head()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal-length</th>\n",
              "      <th>sepal-width</th>\n",
              "      <th>petal-length</th>\n",
              "      <th>petal-width</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal-length  sepal-width  petal-length  petal-width        Class\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MDAXHgbB1RB",
        "colab_type": "text"
      },
      "source": [
        "You can see that our dataset has five columns. The task is to predict the class (which are the values in the fifth column) that the iris plant belongs to, which is based upon the sepal-length, sepal-width, petal-length and petal-width (the first four columns). The next step is to split our dataset into attributes and labels. Execute the following script to do so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC27pDBAB2Rw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "549839dc-06ff-47c8-d8b4-b3bb337ffeb3"
      },
      "source": [
        "# Assign data from first four columns to X variable\n",
        "X = irisdata.iloc[:, 0:4]\n",
        "\n",
        "# Assign data from first fifth columns to y variable\n",
        "y = irisdata.select_dtypes(include=[object])\n",
        "\n",
        "y.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Class\n",
              "0  Iris-setosa\n",
              "1  Iris-setosa\n",
              "2  Iris-setosa\n",
              "3  Iris-setosa\n",
              "4  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmJ4QxRBB-BU",
        "colab_type": "text"
      },
      "source": [
        "You can see that the values in the y series are categorical. However, neural networks work better with numerical data. Our next task is to convert these categorical values to numerical values. But first let's see how many unique values we have in our y series. Execute the following script:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbP6Z1RPB-e7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f27fe68-11ea-477e-93ec-76f766a76aec"
      },
      "source": [
        "y.Class.unique()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biepSAotCGYo",
        "colab_type": "text"
      },
      "source": [
        "We have three unique classes 'Iris-setosa', 'Iris-versicolor' and 'Iris-virginica'. Let's convert these categorical values to numerical values. To do so we will use Scikit-Learn's LabelEncoder class.\n",
        "\n",
        "Execute the following script:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReAvnaXeCH3P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "270af5d5-3722-4b28-9ad3-2266064270e8"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "y = y.apply(le.fit_transform)\n",
        "\n",
        "#let's see how y changed\n",
        "y.Class.unique()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFy7TtWoCLRr",
        "colab_type": "text"
      },
      "source": [
        "**Train Test Split**\n",
        "\n",
        "To avoid over-fitting, we will divide our dataset into training and test splits. The training data will be used to train the neural network and the test data will be used to **evaluate the performance** of the neural network. This helps with the problem of over-fitting because we're evaluating our neural network on data that it has not seen (i.e. been trained on) before.\n",
        "\n",
        "sklearn gives has a train_test_split tool that we will use below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4IPaKyrCLaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nmw1lPvkCLj3",
        "colab_type": "text"
      },
      "source": [
        "**Feature Scaling**\n",
        "\n",
        "Before making actual predictions, it is always a good practice to scale the features so that all of them can be uniformly evaluated.\n",
        "\n",
        "sklearn's StandardScaler can be used for this task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koxzVciXCLtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NogTgXkzCL1m",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olCgWs-uDFLo",
        "colab_type": "text"
      },
      "source": [
        "# Training and Predictions\n",
        "\n",
        "And now it's finally time to train a neural network!\n",
        "\n",
        "we will use the **Multi Layer Perceptron (MLP)** architecture for our classification task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_05Ua35uCL9d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "ed9dc662-090f-44e7-813e-88acbcb8d20a"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
        "mlp.fit(X_train, y_train.values.ravel())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(10, 10, 10), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
              "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
              "              validation_fraction=0.1, verbose=False, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M1f6FR5CMEv",
        "colab_type": "text"
      },
      "source": [
        "Let's go through the three lines of code above:\n",
        "\n",
        "The first step is to import the MLPClassifier class from the sklearn.neural_network library. In the second line, this class is initialized with two parameters.\n",
        "\n",
        "The first parameter, hidden_layer_sizes, is used to set the size of the hidden layers. In our script we will create three layers of 10 nodes each. There is no standard formula for choosing the number of layers and nodes for a neural network and it varies quite a bit depending on the problem at hand. The best way is to try different combinations and see what works best.\n",
        "\n",
        "The second parameter to MLPClassifier specifies the number of iterations, or the epochs, that you want your neural network to execute. Remember, one epoch is a combination of one cycle of feed-forward and back propagation phase.\n",
        "\n",
        "By default the 'relu' activation function is used with 'adam' cost optimizer. However, you can change these functions using the activation and solver parameters, respectively.\n",
        "\n",
        "In the third line the fit function is used to train the algorithm on our training data i.e. X_train and y_train.\n",
        " \n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQxap0QDECpx",
        "colab_type": "text"
      },
      "source": [
        "   \n",
        "The final step is to make predictions on our test data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJxH528aCMLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = mlp.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cenHznOF5Xfj",
        "colab_type": "text"
      },
      "source": [
        "**Scikit Learn (sklearn)** is an open source python library for machine learning and provides many supervised and unsupervised training algorithms\n",
        "\n",
        "In the lectur, we talked about **Multi-Layer Perceptron (MLP)**. We will use this architecture for building our neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGOhUTD2CFv_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B9uGKRt4Vnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWKvvdKSELex",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating the Algorithm\n",
        "We created our algorithm and we made some predictions on the test dataset. Now is the time to evaluate how well our algorithm performs. To evaluate an algorithm, the most commonly used metrics are a confusion matrix, precision, recall, and f1 score. The confusion_matrix and classification_report methods of the sklearn.metrics library can help us find these scores. The following script generates evaluation report for our algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gotHb7AEX0H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f29cb036-9bf3-48ed-d4db-3a3e3d83967a"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test,predictions))\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 9  0  0]\n",
            " [ 0  4  1]\n",
            " [ 0  1 15]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         9\n",
            "           1       0.80      0.80      0.80         5\n",
            "           2       0.94      0.94      0.94        16\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.91      0.91      0.91        30\n",
            "weighted avg       0.93      0.93      0.93        30\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-DmzJk1EgCf",
        "colab_type": "text"
      },
      "source": [
        "You can see from the confusion matrix that our neural network only misclassified two plants out of the 30 plants we tested the network on. Also, the f1 score of 0.93 is very good, given the fact that we only had 150 instances to train.\n",
        "\n",
        "Your results can be slightly different from these because train_test_split randomly splits data into training and test sets, so our networks may not have been trained/tested on the same data. But overall, the accuracy should be greater than 90% on your datasets as well."
      ]
    }
  ]
}